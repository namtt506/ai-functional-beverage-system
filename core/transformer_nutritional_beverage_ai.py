"""
åŸºäºTransformeræ¶æ„çš„è¥å…»é¥®å“é…æ–¹AIç³»ç»Ÿ
ä¸“é—¨ç”¨äºç ”å‘åŸºäºè¥å…»è¡¥å……å‰‚åŸæ–™çš„ç°åˆ¶é¥®å“é…æ–¹
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import math
import random
import numpy as np
from typing import List, Dict, Tuple
import json

# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

# è¥å…»æˆåˆ†è¯å…¸
NUTRIENT_VOCAB = {
    0: '<PAD>', 1: '<START>', 2: '<END>', 3: '<UNK>',
    'ç»´ç”Ÿç´ C': 4, 'ç»´ç”Ÿç´ B1': 5, 'ç»´ç”Ÿç´ B2': 6, 'ç»´ç”Ÿç´ B6': 7, 'ç»´ç”Ÿç´ B12': 8,
    'ç»´ç”Ÿç´ D': 9, 'ç»´ç”Ÿç´ E': 10, 'å¶é…¸': 11, 'çƒŸé…¸': 12, 'æ³›é…¸': 13,
    'é’™': 14, 'é“': 15, 'é”Œ': 16, 'é•': 17, 'é’¾': 18, 'é’ ': 19,
    'ç£·': 20, 'ç¡’': 21, 'é“œ': 22, 'é”°': 23, 'é“¬': 24, 'é’¼': 25,
    'è›‹ç™½è´¨': 26, 'ä¹³æ¸…è›‹ç™½': 27, 'æ¤ç‰©è›‹ç™½': 28, 'èƒ¶åŸè›‹ç™½': 29,
    'ç›Šç”ŸèŒ': 30, 'ç›Šç”Ÿå…ƒ': 31, 'è†³é£Ÿçº¤ç»´': 32, 'Omega-3': 33,
    'ç»¿èŒ¶æå–ç‰©': 34, 'è‘¡è„ç±½æå–ç‰©': 35, 'å§œé»„ç´ ': 36, 'è¾…é…¶Q10': 37,
    'èŠ¦èŸæå–ç‰©': 38, 'äººå‚æå–ç‰©': 39, 'æ¸ææå–ç‰©': 40, 'çº¢æ£æå–ç‰©': 41,
    'èœ‚èœœ': 42, 'æŸ æª¬é…¸': 43, 'è‹¹æœé…¸': 44, 'ä¹³é…¸': 45
}

# åå‘è¯å…¸
NUTRIENT_IDX_TO_TOKEN = {v: k for k, v in NUTRIENT_VOCAB.items()}

# ç›®æ ‡äººç¾¤æ ‡ç­¾
CONSUMER_GROUPS = {
    'ä¸Šç­æ—': 0,
    'å­¦ç”Ÿ': 1,
    'ä¸­è€å¹´äºº': 2,
    'å¥èº«äººç¾¤': 3,
    'çˆ±ç¾äººå£«': 4
}

# å¥åº·åŠŸæ•ˆæ ‡ç­¾
HEALTH_BENEFITS = {
    'å¢å¼ºå…ç–«åŠ›': 0,
    'æŠ—æ°§åŒ–': 1,
    'ä¿ƒè¿›èƒ¶åŸè›‹ç™½åˆæˆ': 2,
    'èƒ½é‡ä»£è°¢': 3,
    'ç¥ç»ç³»ç»Ÿå¥åº·': 4,
    'æŠ—å‹åŠ›': 5,
    'å¿ƒè¡€ç®¡å¥åº·': 6,
    'è„‘éƒ¨å‘è‚²': 7,
    'æŠ—ç‚': 8,
    'å…¨é¢è¥å…»': 9,
    'éª¨éª¼å¥åº·': 10,
    'è®¤çŸ¥åŠŸèƒ½': 11,
    'è‚Œè‚‰å¢é•¿': 12,
    'ä½“åŠ›æ¢å¤': 13,
    'è¥å…»è¡¥å……': 14,
    'è‚ é“å¥åº·': 15,
    'å…ç–«è°ƒèŠ‚': 16,
    'è¥å…»å¸æ”¶': 17,
    'è¡¥è¡€': 18,
    'æ»‹é˜´': 19,
    'ç¾å®¹å…»é¢œ': 20,
    'å¢å¼ºè®°å¿†åŠ›': 21,
    'æŠ—ç–²åŠ³': 22,
    'æ”¹å–„ç¡çœ ': 23,
    'ç”Ÿé•¿å‘è‚²': 24,
    'çš®è‚¤å¥åº·': 25,
    'å¤´å‘å¼ºéŸ§': 26,
    'å‡è‚¥': 27,
    'å…³èŠ‚å¥åº·': 28,
    'å‘³è§‰åŠŸèƒ½': 29,
    'ä¼¤å£æ„ˆåˆ': 30,
    'è‚Œè‚‰åŠŸèƒ½': 31,
    'ç‰™é½¿å¥åº·': 32,
    'è‚Œè‚‰æ”¾æ¾': 33
}

# åŸºç¡€é¥®å“è½½ä½“
BASE_BEVERAGES = {
    'çº¯å‡€æ°´': 0,
    'æ¤°å­æ°´': 1,
    'ç‡•éº¦å¥¶': 2,
    'æä»å¥¶': 3,
    'ç»¿èŒ¶': 4,
    'èŠ±è‰èŒ¶': 5
}

class MultiHeadAttention(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, d_model: int, num_heads: int):
        super(MultiHeadAttention, self).__init__()
        assert d_model % num_heads == 0
        
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)
        
    def scaled_dot_product_attention(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask=None):
        """ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›"""
        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)
        
        attn_probs = torch.softmax(attn_scores, dim=-1)
        output = torch.matmul(attn_probs, V)
        return output
        
    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask=None):
        """å‰å‘ä¼ æ’­"""
        batch_size = query.size(0)
        
        # çº¿æ€§å˜æ¢å¹¶åˆ†å‰²æˆå¤šå¤´
        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        
        # è®¡ç®—æ³¨æ„åŠ›
        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)
        
        # åˆå¹¶å¤šå¤´
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)
        
        # è¾“å‡ºçº¿æ€§å˜æ¢
        output = self.W_o(attn_output)
        return output

class PositionWiseFeedForward(nn.Module):
    """ä½ç½®å‰é¦ˆç½‘ç»œ"""
    
    def __init__(self, d_model: int, d_ff: int):
        super(PositionWiseFeedForward, self).__init__()
        self.fc1 = nn.Linear(d_model, d_ff)
        self.fc2 = nn.Linear(d_ff, d_model)
        self.relu = nn.ReLU()
        
    def forward(self, x: torch.Tensor):
        """å‰å‘ä¼ æ’­"""
        return self.fc2(self.relu(self.fc1(x)))

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    
    def __init__(self, d_model: int, max_seq_length: int):
        super(PositionalEncoding, self).__init__()
        
        pe = torch.zeros(max_seq_length, d_model)
        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
    def forward(self, x: torch.Tensor):
        """å‰å‘ä¼ æ’­"""
        return x + self.pe[:, :x.size(1)]

class EncoderLayer(nn.Module):
    """ç¼–ç å™¨å±‚"""
    
    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float):
        super(EncoderLayer, self).__init__()
        self.self_attn = MultiHeadAttention(d_model, num_heads)
        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x: torch.Tensor, mask: torch.Tensor):
        """å‰å‘ä¼ æ’­"""
        attn_output = self.self_attn(x, x, x, mask)
        x = self.norm1(x + self.dropout(attn_output))
        ff_output = self.feed_forward(x)
        x = self.norm2(x + self.dropout(ff_output))
        return x

class NutritionalBeverageTransformer(nn.Module):
    """è¥å…»é¥®å“é…æ–¹Transformeræ¨¡å‹"""
    
    def __init__(self, 
                 vocab_size: int = len(NUTRIENT_VOCAB),
                 d_model: int = 256,
                 num_heads: int = 8,
                 num_layers: int = 6,
                 d_ff: int = 512,
                 max_seq_length: int = 30,
                 dropout: float = 0.1,
                 num_consumer_groups: int = len(CONSUMER_GROUPS),
                 num_health_benefits: int = len(HEALTH_BENEFITS),
                 num_base_beverages: int = len(BASE_BEVERAGES)):
        super(NutritionalBeverageTransformer, self).__init__()
        
        self.d_model = d_model
        self.max_seq_length = max_seq_length
        
        # åµŒå…¥å±‚
        self.nutrient_embedding = nn.Embedding(vocab_size, d_model)
        self.consumer_embedding = nn.Embedding(num_consumer_groups, d_model)
        self.benefit_embedding = nn.Embedding(num_health_benefits, d_model)
        self.base_beverage_embedding = nn.Embedding(num_base_beverages, d_model)
        
        # ä½ç½®ç¼–ç 
        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)
        
        # ç¼–ç å™¨å±‚
        self.encoder_layers = nn.ModuleList([
            EncoderLayer(d_model, num_heads, d_ff, dropout) 
            for _ in range(num_layers)
        ])
        
        # è§£ç å™¨å±‚ï¼ˆç”¨äºé…æ–¹ç”Ÿæˆï¼‰
        self.decoder_layers = nn.ModuleList([
            EncoderLayer(d_model, num_heads, d_ff, dropout) 
            for _ in range(num_layers)
        ])
        
        # è¾“å‡ºå±‚
        self.nutrient_predictor = nn.Linear(d_model, vocab_size)
        self.base_beverage_predictor = nn.Linear(d_model, num_base_beverages)
        self.health_score_predictor = nn.Linear(d_model, 1)
        self.taste_score_predictor = nn.Linear(d_model, 1)
        
        self.dropout = nn.Dropout(dropout)
        
    def generate_mask(self, seq: torch.Tensor):
        """ç”Ÿæˆæ³¨æ„åŠ›æ©ç """
        mask = (seq != 0).unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, seq_len]
        return mask
        
    def forward(self, 
                nutrient_seq: torch.Tensor = None,
                consumer_group: torch.Tensor = None,
                health_benefits: torch.Tensor = None,
                base_beverage: torch.Tensor = None,
                mode: str = 'predict'):
        """
        å‰å‘ä¼ æ’­
        mode: 'predict' - æ ¹æ®æˆåˆ†é¢„æµ‹å±æ€§
              'generate' - æ ¹æ®ç›®æ ‡ç”Ÿæˆé…æ–¹
        """
        
        if mode == 'predict':
            return self.predict_properties(nutrient_seq)
        else:
            return self.generate_formulation(consumer_group, health_benefits)
    
    def predict_properties(self, nutrient_seq: torch.Tensor):
        """æ ¹æ®è¥å…»æˆåˆ†åºåˆ—é¢„æµ‹é¥®å“å±æ€§"""
        batch_size, seq_len = nutrient_seq.size()
        
        # æˆåˆ†åµŒå…¥å’Œä½ç½®ç¼–ç 
        nutrient_embed = self.nutrient_embedding(nutrient_seq)  # [batch, seq_len, d_model]
        nutrient_embed = self.positional_encoding(nutrient_embed)
        nutrient_embed = self.dropout(nutrient_embed)
        
        # ç”Ÿæˆæ©ç 
        mask = self.generate_mask(nutrient_seq)
        
        # ç¼–ç å™¨å¤„ç†
        enc_output = nutrient_embed
        for enc_layer in self.encoder_layers:
            enc_output = enc_layer(enc_output, mask)
        
        # å…¨å±€æ± åŒ–è·å–åºåˆ—è¡¨ç¤º
        seq_representation = enc_output.mean(dim=1)  # [batch, d_model]
        
        # å±æ€§é¢„æµ‹
        nutrient_logits = self.nutrient_predictor(enc_output)  # [batch, seq_len, vocab_size]
        health_score = torch.sigmoid(self.health_score_predictor(seq_representation))  # [batch, 1]
        taste_score = torch.sigmoid(self.taste_score_predictor(seq_representation))    # [batch, 1]
        base_beverage_logits = self.base_beverage_predictor(seq_representation)         # [batch, num_base_beverages]
        
        return {
            'nutrient_logits': nutrient_logits,
            'health_score': health_score,
            'taste_score': taste_score,
            'base_beverage_logits': base_beverage_logits,
            'seq_representation': seq_representation
        }
    
    def generate_formulation(self, consumer_group: torch.Tensor, health_benefits: torch.Tensor):
        """æ ¹æ®ç›®æ ‡äººç¾¤å’Œå¥åº·éœ€æ±‚ç”Ÿæˆé…æ–¹"""
        batch_size = consumer_group.size(0)
        
        # ç›®æ ‡åµŒå…¥
        consumer_embed = self.consumer_embedding(consumer_group)  # [batch, d_model]
        benefit_embed = self.benefit_embedding(health_benefits)   # [batch, d_model]
        
        # åˆå¹¶ç›®æ ‡ä¿¡æ¯
        target_embed = consumer_embed + benefit_embed  # [batch, d_model]
        
        # æ‰©å±•ä¸ºç›®æ ‡åºåˆ—
        target_seq = target_embed.unsqueeze(1).expand(-1, self.max_seq_length, -1)  # [batch, seq_len, d_model]
        target_seq = self.positional_encoding(target_seq)
        target_seq = self.dropout(target_seq)
        
        # ç”Ÿæˆæ©ç 
        dummy_mask = torch.ones(batch_size, 1, 1, self.max_seq_length).to(target_seq.device)
        
        # è§£ç å™¨å¤„ç†
        dec_output = target_seq
        for dec_layer in self.decoder_layers:
            dec_output = dec_layer(dec_output, dummy_mask)
        
        # é…æ–¹ç”Ÿæˆ
        nutrient_logits = self.nutrient_predictor(dec_output)      # [batch, seq_len, vocab_size]
        base_beverage_logits = self.base_beverage_predictor(dec_output.mean(dim=1))  # [batch, num_base_beverages]
        
        return {
            'nutrient_logits': nutrient_logits,
            'base_beverage_logits': base_beverage_logits,
            'decoder_output': dec_output
        }

class NutritionalBeverageDataset:
    """è¥å…»é¥®å“æ•°æ®é›†"""
    
    def __init__(self):
        self.nutrient_vocab = NUTRIENT_VOCAB
        self.consumer_groups = CONSUMER_GROUPS
        self.health_benefits = HEALTH_BENEFITS
        self.base_beverages = BASE_BEVERAGES
        
        # è¥å…»æˆåˆ†åŠŸæ•ˆæ˜ å°„
        self.nutrient_benefits = {
            'ç»´ç”Ÿç´ C': ['å¢å¼ºå…ç–«åŠ›', 'æŠ—æ°§åŒ–', 'ä¿ƒè¿›èƒ¶åŸè›‹ç™½åˆæˆ'],
            'ç»´ç”Ÿç´ E': ['æŠ—æ°§åŒ–', 'ç¾å®¹å…»é¢œ', 'å¿ƒè¡€ç®¡å¥åº·'],
            'é’™': ['éª¨éª¼å¥åº·', 'ç‰™é½¿å¥åº·', 'è‚Œè‚‰åŠŸèƒ½'],
            'é“': ['è¡¥è¡€', 'å¢å¼ºå…ç–«åŠ›', 'å‘³è§‰åŠŸèƒ½'],
            'é”Œ': ['å…ç–«è°ƒèŠ‚', 'ä¼¤å£æ„ˆåˆ', 'å‘³è§‰åŠŸèƒ½'],
            'é•': ['è‚Œè‚‰æ”¾æ¾', 'ç¥ç»ç³»ç»Ÿå¥åº·', 'å¿ƒè¡€ç®¡å¥åº·'],
            'è›‹ç™½è´¨': ['è‚Œè‚‰å¢é•¿', 'ä½“åŠ›æ¢å¤', 'è¥å…»è¡¥å……'],
            'ä¹³æ¸…è›‹ç™½': ['è‚Œè‚‰å¢é•¿', 'ä½“åŠ›æ¢å¤'],
            'èƒ¶åŸè›‹ç™½': ['ç¾å®¹å…»é¢œ', 'çš®è‚¤å¥åº·', 'å…³èŠ‚å¥åº·'],
            'ç›Šç”ŸèŒ': ['è‚ é“å¥åº·', 'å…ç–«è°ƒèŠ‚', 'è¥å…»å¸æ”¶'],
            'ç»¿èŒ¶æå–ç‰©': ['æŠ—æ°§åŒ–', 'å‡è‚¥', 'å¿ƒè¡€ç®¡å¥åº·'],
            'å§œé»„ç´ ': ['æŠ—ç‚', 'æŠ—æ°§åŒ–', 'å…³èŠ‚å¥åº·']
        }
        
        # ç›®æ ‡äººç¾¤åå¥½æ˜ å°„
        self.consumer_preferences = {
            'ä¸Šç­æ—': {
                'preferred_nutrients': ['ç»´ç”Ÿç´ C', 'ç»´ç”Ÿç´ Bç¾¤', 'è›‹ç™½è´¨'],
                'health_needs': ['å¢å¼ºå…ç–«åŠ›', 'æŠ—ç–²åŠ³', 'æŠ—å‹åŠ›'],
                'base_beverage': 'ç»¿èŒ¶'
            },
            'å­¦ç”Ÿ': {
                'preferred_nutrients': ['ç»´ç”Ÿç´ Bç¾¤', 'è›‹ç™½è´¨', 'Omega-3'],
                'health_needs': ['å¢å¼ºè®°å¿†åŠ›', 'æŠ—ç–²åŠ³', 'è¥å…»è¡¥å……'],
                'base_beverage': 'çº¯å‡€æ°´'
            },
            'ä¸­è€å¹´äºº': {
                'preferred_nutrients': ['é’™', 'ç»´ç”Ÿç´ D', 'Omega-3'],
                'health_needs': ['éª¨éª¼å¥åº·', 'å¿ƒè¡€ç®¡å¥åº·', 'è®¤çŸ¥åŠŸèƒ½'],
                'base_beverage': 'èŠ±è‰èŒ¶'
            },
            'å¥èº«äººç¾¤': {
                'preferred_nutrients': ['è›‹ç™½è´¨', 'BCAA', 'ç”µè§£è´¨'],
                'health_needs': ['è‚Œè‚‰å¢é•¿', 'ä½“åŠ›æ¢å¤', 'èƒ½é‡ä»£è°¢'],
                'base_beverage': 'æ¤°å­æ°´'
            },
            'çˆ±ç¾äººå£«': {
                'preferred_nutrients': ['èƒ¶åŸè›‹ç™½', 'ç»´ç”Ÿç´ C', 'ç»´ç”Ÿç´ E'],
                'health_needs': ['ç¾å®¹å…»é¢œ', 'æŠ—æ°§åŒ–', 'çš®è‚¤å¥åº·'],
                'base_beverage': 'ç‡•éº¦å¥¶'
            }
        }
    
    def generate_sample(self, consumer_group_name: str) -> Dict:
        """ç”Ÿæˆå•ä¸ªè®­ç»ƒæ ·æœ¬"""
        # è·å–ç›®æ ‡äººç¾¤åå¥½
        preferences = self.consumer_preferences[consumer_group_name]
        
        # ç”Ÿæˆè¥å…»æˆåˆ†åºåˆ—
        nutrients = preferences['preferred_nutrients'].copy()
        
        # æ·»åŠ ä¸€äº›éšæœºæˆåˆ†
        all_nutrients = list(self.nutrient_vocab.keys())[4:]  # è·³è¿‡ç‰¹æ®Šæ ‡è®°
        additional_nutrients = random.sample(all_nutrients, k=min(3, len(all_nutrients)))
        nutrients.extend(additional_nutrients)
        
        # è½¬æ¢ä¸ºç´¢å¼•åºåˆ—
        nutrient_indices = [1]  # <START>
        for nutrient in nutrients:
            if nutrient in self.nutrient_vocab:
                nutrient_indices.append(self.nutrient_vocab[nutrient])
            else:
                nutrient_indices.append(3)  # <UNK>
        nutrient_indices.append(2)  # <END>
        
        # å¡«å……æˆ–æˆªæ–­åˆ°å›ºå®šé•¿åº¦
        max_length = 15
        if len(nutrient_indices) < max_length:
            nutrient_indices.extend([0] * (max_length - len(nutrient_indices)))  # <PAD>
        else:
            nutrient_indices = nutrient_indices[:max_length]
        
        # ç›®æ ‡æ ‡ç­¾
        consumer_group_idx = self.consumer_groups[consumer_group_name]
        health_benefit_idx = self.health_benefits[random.choice(preferences['health_needs'])]
        base_beverage_idx = self.base_beverages[preferences['base_beverage']]
        
        return {
            'nutrient_seq': nutrient_indices,
            'consumer_group': consumer_group_idx,
            'health_benefit': health_benefit_idx,
            'base_beverage': base_beverage_idx,
            'health_score': random.uniform(0.7, 1.0),
            'taste_score': random.uniform(0.6, 0.9)
        }
    
    def generate_batch(self, batch_size: int = 32) -> Dict[str, torch.Tensor]:
        """ç”Ÿæˆæ‰¹æ¬¡æ•°æ®"""
        consumer_groups = random.choices(list(self.consumer_groups.keys()), k=batch_size)
        samples = [self.generate_sample(group) for group in consumer_groups]
        
        # è½¬æ¢ä¸ºå¼ é‡
        nutrient_seqs = torch.tensor([s['nutrient_seq'] for s in samples], dtype=torch.long)
        consumer_groups = torch.tensor([s['consumer_group'] for s in samples], dtype=torch.long)
        health_benefits = torch.tensor([s['health_benefit'] for s in samples], dtype=torch.long)
        base_beverages = torch.tensor([s['base_beverage'] for s in samples], dtype=torch.long)
        health_scores = torch.tensor([[s['health_score']] for s in samples], dtype=torch.float)
        taste_scores = torch.tensor([[s['taste_score']] for s in samples], dtype=torch.float)
        
        return {
            'nutrient_seq': nutrient_seqs,
            'consumer_group': consumer_groups,
            'health_benefit': health_benefits,
            'base_beverage': base_beverages,
            'health_score': health_scores,
            'taste_score': taste_scores
        }

def train_model():
    """è®­ç»ƒæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒè¥å…»é¥®å“é…æ–¹Transformeræ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®é›†
    model = NutritionalBeverageTransformer()
    dataset = NutritionalBeverageDataset()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰GPUå¯ç”¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss(ignore_index=0)  # å¿½ç•¥PADæ ‡è®°
    
    # è®­ç»ƒå¾ªç¯
    num_epochs = 100
    batch_size = 32
    
    print(f"ğŸ“¦ è®­ç»ƒå‚æ•°:")
    print(f"   - è®¾å¤‡: {device}")
    print(f"   - Epochs: {num_epochs}")
    print(f"   - Batch Size: {batch_size}")
    print(f"   - æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    model.train()
    for epoch in range(num_epochs):
        # ç”Ÿæˆæ‰¹æ¬¡æ•°æ®
        batch_data = dataset.generate_batch(batch_size)
        
        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        nutrient_seq = batch_data['nutrient_seq'].to(device)
        consumer_group = batch_data['consumer_group'].to(device)
        health_benefit = batch_data['health_benefit'].to(device)
        base_beverage = batch_data['base_beverage'].to(device)
        health_score = batch_data['health_score'].to(device)
        taste_score = batch_data['taste_score'].to(device)
        
        # å‰å‘ä¼ æ’­ (å±æ€§é¢„æµ‹)
        outputs = model(nutrient_seq=nutrient_seq, mode='predict')
        
        # è®¡ç®—æŸå¤±
        # æˆåˆ†é¢„æµ‹æŸå¤±
        nutrient_logits = outputs['nutrient_logits'].view(-1, len(NUTRIENT_VOCAB))
        nutrient_targets = nutrient_seq.view(-1)
        nutrient_loss = criterion(nutrient_logits, nutrient_targets)
        
        # å¥åº·è¯„åˆ†æŸå¤±
        health_loss = F.mse_loss(outputs['health_score'], health_score)
        
        # å£æ„Ÿè¯„åˆ†æŸå¤±
        taste_loss = F.mse_loss(outputs['taste_score'], taste_score)
        
        # åŸºç¡€é¥®å“æŸå¤±
        base_beverage_loss = F.cross_entropy(outputs['base_beverage_logits'], base_beverage)
        
        # æ€»æŸå¤±
        total_loss = nutrient_loss + health_loss + taste_loss + base_beverage_loss
        
        # åå‘ä¼ æ’­å’Œä¼˜åŒ–
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        # æ‰“å°è¿›åº¦
        if (epoch + 1) % 20 == 0:
            print(f" Epoch [{epoch+1}/{num_epochs}], æ€»æŸå¤±: {total_loss.item():.4f}")
            print(f"   - æˆåˆ†æŸå¤±: {nutrient_loss.item():.4f}")
            print(f"   - å¥åº·è¯„åˆ†æŸå¤±: {health_loss.item():.4f}")
            print(f"   - å£æ„Ÿè¯„åˆ†æŸå¤±: {taste_loss.item():.4f}")
            print(f"   - åŸºç¡€é¥®å“æŸå¤±: {base_beverage_loss.item():.4f}")
    
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    return model

def demonstrate_model():
    """æ¼”ç¤ºæ¨¡å‹åŠŸèƒ½"""
    print("\nğŸ§ª æ¨¡å‹åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®é›†
    model = NutritionalBeverageTransformer()
    dataset = NutritionalBeverageDataset()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰GPUå¯ç”¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    
    # æ¼”ç¤º1: å±æ€§é¢„æµ‹
    print("\n1. ğŸ“Š æˆåˆ†å±æ€§é¢„æµ‹æ¼”ç¤º")
    print("-" * 30)
    
    sample_data = dataset.generate_batch(1)
    nutrient_seq = sample_data['nutrient_seq'].to(device)
    
    with torch.no_grad():
        outputs = model(nutrient_seq=nutrient_seq, mode='predict')
    
    # è§£ç æˆåˆ†åºåˆ—
    seq_indices = nutrient_seq[0].cpu().numpy()
    ingredients = []
    for idx in seq_indices:
        if idx in NUTRIENT_IDX_TO_TOKEN and idx != 0:  # éPAD
            ingredients.append(NUTRIENT_IDX_TO_TOKEN[idx])
    
    print(f"è¾“å…¥æˆåˆ†åºåˆ—: {' -> '.join(ingredients)}")
    print(f"å¥åº·è¯„åˆ†é¢„æµ‹: {outputs['health_score'][0].item():.3f}")
    print(f"å£æ„Ÿè¯„åˆ†é¢„æµ‹: {outputs['taste_score'][0].item():.3f}")
    
    # é¢„æµ‹åŸºç¡€é¥®å“
    base_beverage_logits = outputs['base_beverage_logits'][0]
    base_beverage_probs = F.softmax(base_beverage_logits, dim=0)
    best_beverage_idx = torch.argmax(base_beverage_probs).item()
    best_beverage = list(BASE_BEVERAGES.keys())[best_beverage_idx]
    confidence = base_beverage_probs[best_beverage_idx].item()
    print(f"æ¨èåŸºç¡€é¥®å“: {best_beverage} (ç½®ä¿¡åº¦: {confidence:.3f})")
    
    # æ¼”ç¤º2: é…æ–¹ç”Ÿæˆ
    print("\n2. ğŸ§ª é…æ–¹ç”Ÿæˆæ¼”ç¤º")
    print("-" * 30)
    
    consumer_group = torch.tensor([CONSUMER_GROUPS['ä¸Šç­æ—']], dtype=torch.long).to(device)
    health_benefit = torch.tensor([HEALTH_BENEFITS['å¢å¼ºå…ç–«åŠ›']], dtype=torch.long).to(device)
    
    with torch.no_grad():
        outputs = model(consumer_group=consumer_group, health_benefits=health_benefit, mode='generate')
    
    # è§£ç ç”Ÿæˆçš„æˆåˆ†
    nutrient_logits = outputs['nutrient_logits'][0]  # ç¬¬ä¸€ä¸ªæ ·æœ¬
    generated_indices = torch.argmax(nutrient_logits, dim=-1).cpu().numpy()
    
    generated_ingredients = []
    for idx in generated_indices:
        if idx in NUTRIENT_IDX_TO_TOKEN and idx not in [0, 1, 2, 3]:  # éç‰¹æ®Šæ ‡è®°
            ingredient = NUTRIENT_IDX_TO_TOKEN[idx]
            if ingredient not in generated_ingredients:  # å»é‡
                generated_ingredients.append(ingredient)
    
    print(f"ç›®æ ‡äººç¾¤: ä¸Šç­æ—")
    print(f"å¥åº·éœ€æ±‚: å¢å¼ºå…ç–«åŠ›")
    print(f"ç”Ÿæˆçš„æˆåˆ†: {', '.join(generated_ingredients[:5])}")  # å–å‰5ä¸ª
    
    # é¢„æµ‹åŸºç¡€é¥®å“
    base_beverage_logits = outputs['base_beverage_logits'][0]
    base_beverage_probs = F.softmax(base_beverage_logits, dim=0)
    best_beverage_idx = torch.argmax(base_beverage_probs).item()
    best_beverage = list(BASE_BEVERAGES.keys())[best_beverage_idx]
    confidence = base_beverage_probs[best_beverage_idx].item()
    print(f"æ¨èåŸºç¡€é¥®å“: {best_beverage} (ç½®ä¿¡åº¦: {confidence:.3f})")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥¤ åŸºäºTransformeræ¶æ„çš„è¥å…»é¥®å“é…æ–¹AIç³»ç»Ÿ")
    print("=" * 60)
    print("æœ¬ç³»ç»Ÿä½¿ç”¨è‡ªå®šä¹‰Transformeræ¨¡å‹è¿›è¡Œè¥å…»é¥®å“é…æ–¹ç ”å‘")
    print("ä¸“æ³¨äºå°†è¥å…»è¡¥å……å‰‚åŸæ–™å†åŠ å·¥æˆç°åˆ¶é¥®å“")
    
    # è®­ç»ƒæ¨¡å‹
    model = train_model()
    
    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), 'nutritional_beverage_transformer.pth')
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ° nutritional_beverage_transformer.pth")
    
    # æ¼”ç¤ºæ¨¡å‹åŠŸèƒ½
    demonstrate_model()
    
    print("\nğŸ¯ ç³»ç»Ÿç‰¹ç‚¹:")
    print("âœ… åŸºäºè‡ªå®šä¹‰Transformeræ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹")
    print("âœ… ä¸“é—¨é’ˆå¯¹è¥å…»é¥®å“é…æ–¹ç ”å‘è®¾è®¡")
    print("âœ… æ”¯æŒæˆåˆ†å±æ€§é¢„æµ‹å’Œé…æ–¹ç”Ÿæˆ")
    print("âœ… èåˆç›®æ ‡äººç¾¤å’Œå¥åº·éœ€æ±‚çš„ä¸ªæ€§åŒ–æ¨è")
    print("âœ… å¯æ‰©å±•çš„è¥å…»æˆåˆ†å’Œå¥åº·åŠŸæ•ˆä½“ç³»")
    
    print("\nğŸ“‹ åº”ç”¨ä»·å€¼:")
    print("â€¢ åŠŸèƒ½æ€§é¥®å“åº—äº§å“åˆ›æ–°")
    print("â€¢ å¥åº·é¤é¥®è¥å…»é¥®å“è®¾è®¡")
    print("â€¢ ä¸ªæ€§åŒ–è¥å…»è§£å†³æ–¹æ¡ˆ")
    print("â€¢ è¥å…»è¡¥å……å‰‚è¡Œä¸šäº§å“å¼€å‘")

if __name__ == "__main__":
    main()